## GloVe pre-trained word embeddings

### Download

Go to https://github.com/stanfordnlp/GloVe and find `glove.6B.zip` which is a dataset of Wikipedia 2014 + Gigaword 5 (6B tokens, 400K vocab, uncased, 300d vectors, 822 MB download)
